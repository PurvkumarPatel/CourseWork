{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103158,"status":"ok","timestamp":1706416671952,"user":{"displayName":"UI21CS43_ Purv Patel","userId":"12796545009456059402"},"user_tz":-330},"id":"P6mrb1WuxZ8m","outputId":"5a0e0c17-1963-4c01-cdf9-e70779b28ee4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["                                             Comment  \\\n","0  I materials had code if i want both displayed ...   \n","1  About time excel got with the picture. But fir...   \n","2  Was this a phased release? My images are showi...   \n","3  Wow!!<br>Thanks a lot for sharing these nice t...   \n","4  This is super helpful and useful as well! Than...   \n","\n","                                       Comment_Lower  \\\n","0  i materials had code if i want both displayed ...   \n","1  about time excel got with the picture. but fir...   \n","2  was this a phased release? my images are showi...   \n","3  wow!!<br>thanks a lot for sharing these nice t...   \n","4  this is super helpful and useful as well! than...   \n","\n","                                              Tokens  \\\n","0  [i, materials, had, code, if, i, want, both, d...   \n","1  [about, time, excel, got, with, the, picture, ...   \n","2  [was, this, a, phased, release, ?, my, images,...   \n","3  [wow, !, !, <, br, >, thanks, a, lot, for, sha...   \n","4  [this, is, super, helpful, and, useful, as, we...   \n","\n","                                      No_Punctuation  \\\n","0  [i, materials, had, code, if, i, want, both, d...   \n","1  [about, time, excel, got, with, the, picture, ...   \n","2  [was, this, a, phased, release, my, images, ar...   \n","3  [wow, br, thanks, a, lot, for, sharing, these,...   \n","4  [this, is, super, helpful, and, useful, as, we...   \n","\n","                                        No_Stopwords  \\\n","0  [materials, code, want, displayed, row, adjuse...   \n","1  [time, excel, got, picture, first, thing, trie...   \n","2  [phased, release, images, showing, text, 39, p...   \n","3      [wow, br, thanks, lot, sharing, nice, tricks]   \n","4              [super, helpful, useful, well, thank]   \n","\n","                                             Stemmed  \\\n","0  [materi, code, want, display, row, adjus, column]   \n","1  [time, excel, got, pictur, first, thing, tri, ...   \n","2  [phase, releas, imag, show, text, 39, pictur, ...   \n","3          [wow, br, thank, lot, share, nice, trick]   \n","4                    [super, help, use, well, thank]   \n","\n","                                          Lemmatized  \\\n","0  [material, code, want, displayed, row, adjusen...   \n","1  [time, excel, got, picture, first, thing, trie...   \n","2  [phased, release, image, showing, text, 39, pi...   \n","3       [wow, br, thanks, lot, sharing, nice, trick]   \n","4              [super, helpful, useful, well, thank]   \n","\n","                                          Translated  \\\n","0  i સામગ્રીમાં કોડ હતો જો હું ઇચ્છું છું કે બંને...   \n","1  સમય વિશેની એક્સેલ ચિત્ર સાથે મળી. પરંતુ મેં જે...   \n","2  શું આ તબક્કાવાર પ્રકાશન હતું? મારી છબીઓ ટેક્સ્...   \n","3  વાહ!!<br>આ સરસ યુક્તિઓ શેર કરવા બદલ ખૂબ ખૂબ આભાર!   \n","4               આ ખૂબ મદદરૂપ અને ઉપયોગી પણ છે! આભાર!   \n","\n","                                          Emoji_Text  \n","0  I materials had code if i want both displayed ...  \n","1  About time excel got with the picture. But fir...  \n","2  Was this a phased release? My images are showi...  \n","3  Wow!!<br>Thanks a lot for sharing these nice t...  \n","4  This is super helpful and useful as well! Than...  \n"]}],"source":["#Performed on youtube comments dataset\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from translate import Translator\n","import emoji\n","from textblob import TextBlob\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","file_path = 'youtube_comments.csv'\n","output_file_path = 'preprocessed_youtube_comments.csv'\n","\n","df = pd.read_csv(file_path)\n","\n","df['Comment_Lower'] = df['Comment'].str.lower()\n","\n","df['Tokens'] = df['Comment_Lower'].apply(nltk.word_tokenize)\n","\n","df['No_Punctuation'] = df['Tokens'].apply(lambda x: [word for word in x if word.isalnum()])\n","\n","stop_words = set(stopwords.words('english'))\n","df['No_Stopwords'] = df['No_Punctuation'].apply(lambda x: [word for word in x if word not in stop_words])\n","\n","stemmer = PorterStemmer()\n","df['Stemmed'] = df['No_Stopwords'].apply(lambda x: [stemmer.stem(word) for word in x])\n","\n","lemmatizer = WordNetLemmatizer()\n","df['Lemmatized'] = df['No_Stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","translator = Translator(to_lang=\"gu\")\n","\n","def translate_to_gujarati(text):\n","    try:\n","        translated = translator.translate(text)\n","        return translated\n","    except:\n","        return text\n","\n","df['Translated'] = df['Comment_Lower'].apply(translate_to_gujarati)\n","\n","df['Emoji_Text'] = df['Comment'].apply(lambda x: emoji.demojize(x))\n","\n","df.to_csv(output_file_path, index=False)\n","\n","print(df.head())\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znknq5t8Uj5r","executionInfo":{"status":"ok","timestamp":1706422825387,"user_tz":-330,"elapsed":5474378,"user":{"displayName":"UI21CS43_ Purv Patel","userId":"12796545009456059402"}},"outputId":"1af5ae6d-2d9e-439e-aba8-14dbbe09b471"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["                  user_name          user_location  \\\n","0              Ravi Shastry  All 3 places possible   \n","1        India Today Sports           Noida, India   \n","2              Augmont Gold                 Mumbai   \n","3        Papa Louie's pizza                    NaN   \n","4  🇮🇳 पंडित जीवेश मिश्रा 🇮🇳  JAUNPUR UP INDIA 🇮🇳🇮🇳   \n","\n","                                    user_description      user_created  \\\n","0  Tracer bullet on TV, Enfield Bullet in life. W...  03-04-2015 14:15   \n","1  Live cricket scores, news, analysis and fun fa...  26-09-2017 10:57   \n","2  With Augmont Gold, you can now invest in as lo...  12-06-2012 12:10   \n","3                                                NaN  18-07-2020 05:36   \n","4  👍 सत्य बोलने के लिए किसी के आदेश की जरूरत नहीं...  01-08-2017 17:24   \n","\n","   user_followers  user_friends  user_favourites  user_verified  \\\n","0             578            66               86          False   \n","1            6434            15               10          False   \n","2            2112            12               17          False   \n","3               1             0                0          False   \n","4              91            86            25251          False   \n","\n","               date                                               text  ...  \\\n","0  17-08-2020 10:54  I interacted with him as a commentator &amp; a...  ...   \n","1  17-08-2020 10:53  \"I don't see myself travelling for cricket aga...  ...   \n","2  17-08-2020 10:52  You will never retire from our hearts!\\n\\n#Aug...  ...   \n","3  17-08-2020 10:51  From winning trophies 🏆 to winning people's he...  ...   \n","4  17-08-2020 10:49  There's no limit to the creativity of some of ...  ...   \n","\n","                source is_retweet  \\\n","0   Twitter for iPhone      False   \n","1      Twitter Web App      False   \n","2      Twitter Web App      False   \n","3  Twitter for Android      False   \n","4  Twitter for Android      False   \n","\n","                                          text_lower  \\\n","0  i interacted with him as a commentator &amp; a...   \n","1  \"i don't see myself travelling for cricket aga...   \n","2  you will never retire from our hearts!\\n\\n#aug...   \n","3  from winning trophies 🏆 to winning people's he...   \n","4  there's no limit to the creativity of some of ...   \n","\n","                                              tokens  \\\n","0  [i, interacted, with, him, as, a, commentator,...   \n","1  [``, i, do, n't, see, myself, travelling, for,...   \n","2  [you, will, never, retire, from, our, hearts, ...   \n","3  [from, winning, trophies, 🏆, to, winning, peop...   \n","4  [there, 's, no, limit, to, the, creativity, of...   \n","\n","                                      no_punctuation  \\\n","0  [i, interacted, with, him, as, a, commentator,...   \n","1  [i, do, see, myself, travelling, for, cricket,...   \n","2  [you, will, never, retire, from, our, hearts, ...   \n","3  [from, winning, trophies, to, winning, people,...   \n","4  [there, no, limit, to, the, creativity, of, so...   \n","\n","                                        no_stopwords  \\\n","0  [interacted, commentator, amp, coach, never, i...   \n","1  [see, travelling, cricket, around, loved, love...   \n","2  [never, retire, hearts, augmontgold, trendingf...   \n","3  [winning, trophies, winning, people, hearts, m...   \n","4  [limit, creativity, tributes, ms, dhoni, sures...   \n","\n","                                             stemmed  \\\n","0  [interact, comment, amp, coach, never, interf,...   \n","1  [see, travel, cricket, around, love, love, bac...   \n","2  [never, retir, heart, augmontgold, trendingfor...   \n","3  [win, trophi, win, peopl, heart, ms, dhoni, th...   \n","4  [limit, creativ, tribut, ms, dhoni, suresh, ra...   \n","\n","                                          lemmatized  \\\n","0  [interacted, commentator, amp, coach, never, i...   \n","1  [see, travelling, cricket, around, loved, love...   \n","2  [never, retire, heart, augmontgold, trendingfo...   \n","3  [winning, trophy, winning, people, heart, m, d...   \n","4  [limit, creativity, tribute, m, dhoni, suresh,...   \n","\n","                                          translated  \\\n","0  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE ...   \n","1  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE ...   \n","2  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE ...   \n","3  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE ...   \n","4  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE ...   \n","\n","                                          emoji_text  \n","0  I interacted with him as a commentator &amp; a...  \n","1  \"I don't see myself travelling for cricket aga...  \n","2  You will never retire from our hearts!\\n\\n#Aug...  \n","3  From winning trophies :trophy: to winning peop...  \n","4  There's no limit to the creativity of some of ...  \n","\n","[5 rows x 21 columns]\n"]}],"source":["# Dataset Given in Assignment\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from translate import Translator\n","import emoji\n","from textblob import TextBlob\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","file_path = 'dhoniretires_tweets.csv'\n","output_file_path = 'preprocessed_dhoniretires_tweets.csv'\n","\n","df = pd.read_csv(file_path)\n","\n","df['text_lower'] = df['text'].str.lower()\n","\n","df['tokens'] = df['text_lower'].apply(nltk.word_tokenize)\n","\n","df['no_punctuation'] = df['tokens'].apply(lambda x: [word for word in x if word.isalnum()])\n","\n","stop_words = set(stopwords.words('english'))\n","df['no_stopwords'] = df['no_punctuation'].apply(lambda x: [word for word in x if word not in stop_words])\n","\n","stemmer = PorterStemmer()\n","df['stemmed'] = df['no_stopwords'].apply(lambda x: [stemmer.stem(word) for word in x])\n","\n","lemmatizer = WordNetLemmatizer()\n","df['lemmatized'] = df['no_stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","translator = Translator(to_lang=\"gu\")\n","\n","def translate_to_gujarati(text):\n","    try:\n","        translated = translator.translate(text)\n","        return translated\n","    except:\n","        return text\n","\n","df['translated'] = df['text_lower'].apply(translate_to_gujarati)\n","\n","df['emoji_text'] = df['text'].apply(lambda x: emoji.demojize(x))\n","\n","df.to_csv(output_file_path, index=False)\n","\n","print(df.head())\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuH2EMLGUlJAfa9X/KC2y9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}